# -*- coding: utf-8 -*-
"""Copy of Base_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m1KvteauOHiq_hGWx032ZODRzcoI7W7c
"""

# Base Model

import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
import itertools

from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
from keras.models import Sequential, Model
from keras.layers import Dense, Activation, Flatten, Dropout, concatenate, Input, Conv2D, MaxPooling2D
from keras.optimizers import Adam, Adadelta
from keras.layers.advanced_activations import LeakyReLU
from keras.utils.np_utils import to_categorical

import scipy.io as sio
My_data = sio.loadmat('drive/Plant Classification Using C-CNN/train/Image_Processed_1data.mat')
x_train = My_data['train']
labels = My_data["train_labels"]

x_train, x_test, y_train, y_test = train_test_split(x_train, labels, test_size = 0.1, random_state=10, stratify =labels)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=10, stratify=y_train)

input_shape = x_train[1].shape
print('Input Shape is :', input_shape)

from keras.layers import MaxPooling2D
from keras.layers import Add
from keras.layers import BatchNormalization
from keras.applications.vgg19 import VGG19
from keras.layers import Activation

#Prepare input for VGG  

#ip= Conv2D(3, (1,1), padding='same')(image)
#Apply VGG

#Creat VGG model
#VGG_model = Model(image_input, out)

#Copy all layers from VGG
#model_new =Sequential()
#image_input=Input(shape=input_shape)
#ip= Conv2D(3, (1,1), padding='same')(image)
#VGG_model =VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling='max', classes=1000)
#for layer in VGG_model.layers:
  #model_new.add(layer)
  
#model_new.layers.pop()
#model_new.layers.pop()

#for layer in model_new.layers:
  #layer.trainable= True
  
#model_new.add(Dropout(0.5))
#model_new.add(Dense(4096))
#model_new.add(Dropout(0.3))
#model_new.add(Dense(12, activation ='softmax'))
#Remove last 2 layer of model copied from VGG
#model_new.layers.pop()
#model_new.layers.pop()

#for layer in model_new.layers:
  #layer.trainable = False
  
##
##BASE Network

image_input=Input(shape=input_shape)
x = Conv2D(32, (11,11), strides=(4, 4), padding='valid')(image_input)
x = LeakyReLU(alpha=0.0)(x)
x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)
x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)

x = Conv2D(48, (5,5), padding='same')(x)
x = LeakyReLU(alpha=0.0)(x)
x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)
x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)


x = Conv2D(64, (3,3), padding='same')(x)
x = LeakyReLU(alpha=0.0)(x)
#x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)
#x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)

x = Conv2D(16, (3,3), padding='same')(x)
x = LeakyReLU(alpha=0.0)(x)

x = Conv2D(16, (3,3), padding='same')(x)
x = LeakyReLU(alpha=0.0)(x)
x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)

x= Flatten()(x)

x= Dense(1024)(x)
x = LeakyReLU(alpha=0.0)(x)


x= Dense(1024)(x)
x = LeakyReLU(alpha=0.0)(x)


out = Dense(12, activation='softmax')(x)

model_new = Model(image_input, out)
model_new.summary()

model_new.compile(optimizer = Adam(lr=.000125) , loss = 'categorical_crossentropy', metrics=['accuracy'])

#%%time

history = model_new.fit(x_train, y_train, epochs=12, batch_size=128)

y_val_pred = model_new.evaluate(x_val, y_val, batch_size=32, verbose=1, sample_weight=None)

print()
print ("Validation Loss = " + str(y_val_pred[0]))
print ("Validation Accuracy = " + str(y_val_pred[1]))

y_test_pred = model_new.evaluate(x_test, y_test, batch_size=32, verbose=1, sample_weight=None)

print()
print ("Test Loss = " + str(y_test_pred[0]))
print ("Test Accuracy = " + str(y_test_pred[1]))

y_train_pred = model_new.evaluate(x_train, y_train, batch_size=32, verbose=1, sample_weight=None)
print ("Train Loss = " + str(y_train_pred[0]))
print ("Train Accuracy = " + str(y_train_pred[1]))

y_train_pred =model_new.predict(x_train, batch_size=64, verbose=1, steps=None)
y_test_pred =model_new.predict(x_test, batch_size=64, verbose=1, steps=None)
y_val_pred =model_new.predict(x_val, batch_size=64, verbose=1, steps=None)

y_train_pred = np.argmax(y_train_pred, axis=1)
y_test_pred = np.argmax(y_test_pred, axis=1)
y_val_pred = np.argmax(y_val_pred, axis=1)

y_train_x = np.argmax(y_train, axis=1)
y_test_x = np.argmax(y_test, axis=1)
y_val_x = np.argmax(y_val, axis=1)

from sklearn.metrics import confusion_matrix
SPECIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen',
              'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse',
              'Small-flowered Cranesbill', 'Sugar beet']

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Confusion matrix")
    else:
        print('Classification Matrix')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

# Compute confusion matrix for Train
cnf_matrix = confusion_matrix(y_train_x, y_train_pred)
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=SPECIES,
                      title='Classification matrix')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=SPECIES, normalize=True,
                      title='Confusion matrix')



plt.show()

# Compute confusion matrix
cnf_matrix = confusion_matrix(y_test_x, y_test_pred)
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=SPECIES,
                      title='Confusion matrix')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=SPECIES, normalize=True,
                      title='Normalized confusion matrix')

plt.show()

# Compute confusion matrix
cnf_matrix = confusion_matrix(y_val_x, y_val_pred)
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=SPECIES,
                      title='Confusion matrix')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=SPECIES, normalize=True,
                      title='Normalized confusion matrix')

plt.show()



from matplotlib import axes as plt2
from matplotlib import pyplot as plt
# summarize history for accuracy
plt.plot(history.history['acc'])
#plt.plot(history.history['val_acc'])
#plt.plot(history.history['loss'])
plt.title('Model accuracy graph')
plt.ylabel('Accuracy')

plt.xlabel('Epoch')
plt.legend(['Accuracy'], loc='upper centre')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
#plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')

plt.show()

